{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument,Doc2Vec, LabeledSentence \n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DocIterator(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "       self.labels_list = labels_list\n",
    "       self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield LabeledSentence(words=doc.split(),tags=[self.labels_list[idx]])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_dv(corpus, vec_size, doc_labels):\n",
    "    it = DocIterator(corpus, doc_labels)\n",
    "    \n",
    "    model = gensim.models.Doc2Vec(vector_size=vec_size, window=10, min_count=2, workers=12,alpha=0.025, min_alpha=0.025, epochs=20, negative=5)\n",
    "    model.build_vocab(it)    \n",
    "    model.train(it, epochs=model.epochs, total_examples=model.corpus_count)\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_location(model, output_path, rank_sizes):\n",
    "    queries = []\n",
    "\n",
    "    queries.append(['state', 'diagram'])\n",
    "    queries.append(['activity', 'diagram'])\n",
    "    queries.append(['use', 'case', 'diagram'])\n",
    "    queries.append(['collaboration', 'diagram'])\n",
    "    queries.append(['deployment', 'diagram'])\n",
    "    queries.append(['sequence', 'diagram'])\n",
    "    queries.append(['cognitive', 'support'])\n",
    "    queries.append(['logging'])\n",
    "\n",
    "    for q in queries:                \n",
    "        # Infer a vector for the query\n",
    "        new_vector = model.infer_vector(q)    \n",
    "        \n",
    "        # Find the most similar documents for the infered vector\n",
    "        simil = model.docvecs.most_similar([new_vector], topn=len(model.docvecs))  \n",
    "        \n",
    "        name_result = name_converter['_'.join(q)] + '.txt'      \n",
    "        \n",
    "        for size in rank_sizes:       \n",
    "            dir_path = os.path.join(output_path, str(size), name_result)\n",
    "            print(\"Processing: R: \", size)\n",
    "            \n",
    "            rank_size = size\n",
    "            if size == 0:\n",
    "                rank_size = len(model.docvecs)\n",
    "            \n",
    "            f = open(dir_path, 'w')\n",
    "            for el in simil[:rank_size]:\n",
    "                entity = el[0].replace('.txt', '')     \n",
    "                \n",
    "                # Remove Inner Methods\n",
    "                if '$' in entity:                    \n",
    "                    continue\n",
    "                \n",
    "                # Replace because the naming file restrictions\n",
    "                entity = entity.replace('{', '<')                        \n",
    "                entity = entity.replace('}', '>')\n",
    "                \n",
    "                # Method result \n",
    "                if '(' in entity:            \n",
    "                    write_form = entity.rsplit('.', 1)\n",
    "                    method = write_form[0]\n",
    "                    method += ' ' + write_form[1]            \n",
    "                    f.write(method + '\\n')\n",
    "                # Class Result\n",
    "                else:    \n",
    "                    f.write(entity + '\\n')\n",
    "\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_converter = {}\n",
    "name_converter['state_diagram'] = 'STATEDIAGRAM'\n",
    "name_converter['activity_diagram'] = 'ACTIVITYDIAGRAM'\n",
    "name_converter['use_case_diagram'] = 'USECASEDIAGRAM'\n",
    "name_converter['collaboration_diagram'] = 'COLLABORATIONDIAGRAM'\n",
    "name_converter['deployment_diagram'] = 'DEPLOYMENTDIAGRAM'\n",
    "name_converter['sequence_diagram'] = 'SEQUENCEDIAGRAM'\n",
    "name_converter['cognitive_support'] = 'COGNITIVE'\n",
    "name_converter['logging'] = 'LOGGING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories_to_process = []\n",
    "directories_to_process.append('RandomConfig00001')\n",
    "directories_to_process.append('RandomConfig00002')\n",
    "directories_to_process.append('RandomConfig00003')\n",
    "directories_to_process.append('RandomConfig00004')\n",
    "directories_to_process.append('RandomConfig00005')\n",
    "directories_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics_comb = [100,200,300,400,500]\n",
    "rank_size_comb = [10, 100, 1000, 0] #0 == Full rank\n",
    "\n",
    "for config in directories_to_process:\n",
    "    text_path = os.path.join(config, 'TEXT')\n",
    "    doc_labels = [] \n",
    "    doc_labels = [f for f in os.listdir(text_path) if f.endswith('.txt')]\n",
    "    data = []\n",
    "    \n",
    "    for doc in doc_labels:\n",
    "        full_path = os.path.join(text_path, doc)\n",
    "        f = open(full_path, 'r')\n",
    "        content = f.read()\n",
    "        data.append(content)\n",
    "    \n",
    "    for n_comb in num_topics_comb:\n",
    "        print(\"Processing: N: \", n_comb)\n",
    "        dv_model = train_dv(data, n_comb, doc_labels) \n",
    "        out_path = os.path.join(config, 'RESULTS', 'DV', str(n_comb))\n",
    "        feature_location(dv_model, out_path, rank_size_comb)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
