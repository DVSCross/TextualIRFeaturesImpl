{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import sys\n",
    "import os\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A entity can be a Class-0 or Method-1\n",
    "class Entity:\n",
    "    def __init__(self, id, pid, name, typ):\n",
    "        self.id = id\n",
    "        self.pid = pid\n",
    "        self.name = name\n",
    "        self.content = []\n",
    "        self.typ = typ\n",
    "        \n",
    "    def add_content(self, content):\n",
    "        self.content.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_replace(text):       \n",
    "    # Because restriction for naming files, '<'  and '>' tokens wil be replaced\n",
    "    # '<' by '{' and\n",
    "    # '>' by '}'\n",
    "    text = text.replace('<','{')\n",
    "    text = text.replace('>', '}')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camel_case_split(text):\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', text)\n",
    "    result = [m.group(0) for m in matches]\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile('([^\\s\\w]|_)+')\n",
    "\n",
    "def content_pre_processing(text):    \n",
    "    # Split the tokens based on camel case, underscores, and non-letters\n",
    "    processed_text = camel_case_split(text)\n",
    "    \n",
    "    # Non-Lettering filtering\n",
    "    processed_text = pattern.sub(' ', processed_text)\n",
    "    \n",
    "    # Remove extra space characters and convert all to lower case\n",
    "    processed_text = ' '.join(processed_text.split()).lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    result = ''.join(i for i in processed_text if not i.isdigit())    \n",
    "    \n",
    "    # Remove english Stopwords and words shorten than 1 character long\n",
    "    result = [token for token in result.split() if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2] \n",
    "        \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_corpus(file, root_folder):    \n",
    "    entities_dict = {}\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()  \n",
    "    \n",
    "    # Extract root entities: Classes and Methods identifications\n",
    "    for entity in root.iter('jent'):\n",
    "        if entity.attrib['type'] == 'method':   \n",
    "            method_id = entity.attrib['id']           \n",
    "            method_pid = entity.attrib['pid']\n",
    "            name = custom_replace(entity.text)\n",
    "            entities_dict[method_id] = Entity(method_id, method_pid, name, 1)\n",
    "            print(method_id,entities_dict[method_id].name)\n",
    "        elif entity.attrib['type'] == 'class' or entity.attrib['type'] == 'interface' or entity.attrib['type'] == 'enum':  \n",
    "            class_id = entity.attrib['id']\n",
    "            class_pid = entity.attrib['pid']\n",
    "            name = custom_replace(entity.text)\n",
    "            entities_dict[class_id] = Entity(class_id, class_pid, name, 0)\n",
    "            print(class_id, entities_dict[class_id].name)         \n",
    "    \n",
    "    # Add the content for each attribute that references the entities described above\n",
    "    for token in root.iter('jtok'):        \n",
    "        eid = token.attrib['eid']  \n",
    "        if eid in entities_dict:            \n",
    "            entities_dict[eid].add_content(token.text)              \n",
    "    \n",
    "    # Write the dictionary to the corpus file (txt)\n",
    "    for key, value in entities_dict.items():    \n",
    "        full_path = os.path.join(root_folder, value.name + '.txt')\n",
    "        full = ' '.join(value.content)        \n",
    "        content = content_pre_processing(full)      \n",
    "        f = open(full_path, 'w', encoding='utf-8')            \n",
    "        f.write(content)  \n",
    "        f.close()\n",
    "\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directories_to_process = []\n",
    "directories_to_process.append('RandomConfig00001')\n",
    "directories_to_process.append('RandomConfig00002')\n",
    "directories_to_process.append('RandomConfig00003')\n",
    "directories_to_process.append('RandomConfig00004')\n",
    "directories_to_process.append('RandomConfig00005')\n",
    "directories_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for directory in directories_to_process:\n",
    "    print('Processing Directory: ', directory)\n",
    "    doc_labels = []\n",
    "    jdoc_path = os.path.join(directory, 'JDOC')\n",
    "    text_path = os.path.join(directory, 'TEXT')\n",
    "    doc_labels = [f for f in os.listdir(jdoc_path) if f.endswith('.jdoc')]    \n",
    "    for doc in doc_labels:\n",
    "        file_path = os.path.join(jdoc_path, doc)\n",
    "        extract_corpus(file_path, text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
